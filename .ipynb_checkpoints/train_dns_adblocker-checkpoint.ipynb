{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS Ad-Blocker Machine Learning Model Training\n",
    "\n",
    "This notebook trains an XGBoost model to classify domains as ads vs legitimate using DNS-level features.\n",
    "\n",
    "## Pipeline:\n",
    "1. Load labeled dataset (198k domains)\n",
    "2. Extract 35 DNS-level features from each domain\n",
    "3. Train XGBoost classifier\n",
    "4. Evaluate performance\n",
    "5. Save model for Raspberry Pi deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dns_feature_extractor import DNSFeatureExtractor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled dataset\n",
    "df = pd.read_csv('dns_training_data.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {len(df)} domains\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nSample domains:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Features from Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature extractor\n",
    "extractor = DNSFeatureExtractor()\n",
    "\n",
    "# Extract features for all domains\n",
    "print(\"Extracting features from domains...\")\n",
    "print(\"This may take a few minutes for 198k domains...\\n\")\n",
    "\n",
    "features_list = []\n",
    "\n",
    "# Use tqdm for progress bar\n",
    "for domain in tqdm(df['domain'], desc=\"Extracting features\"):\n",
    "    try:\n",
    "        features = extractor.extract_features(domain)\n",
    "        features_list.append(features)\n",
    "    except Exception as e:\n",
    "        # If feature extraction fails, create empty feature dict\n",
    "        print(f\"Error extracting features for {domain}: {e}\")\n",
    "        features_list.append({})\n",
    "\n",
    "# Convert to DataFrame\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "print(f\"\\nFeatures extracted: {features_df.shape[1]} features\")\n",
    "print(f\"Feature names: {list(features_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features with labels\n",
    "X = features_df\n",
    "y = df['label']\n",
    "\n",
    "# Handle any missing values (fill with 0)\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Label vector shape: {y.shape}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintain class balance\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nTraining label distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest label distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix for XGBoost (more efficient)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'max_depth': 6,                   # Maximum tree depth\n",
    "    'learning_rate': 0.1,             # Learning rate (eta)\n",
    "    'n_estimators': 100,              # Number of trees\n",
    "    'eval_metric': 'logloss',         # Evaluation metric\n",
    "    'seed': 42,                       # Random seed\n",
    "    'tree_method': 'hist',            # Faster training\n",
    "    'subsample': 0.8,                 # Sample 80% of data for each tree\n",
    "    'colsample_bytree': 0.8,          # Sample 80% of features for each tree\n",
    "}\n",
    "\n",
    "# Watchlist for monitoring training progress\n",
    "evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "print(\"Training XGBoost model...\\n\")\n",
    "\n",
    "# Train the model\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=100,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=10,  # Stop if no improvement for 10 rounds\n",
    "    verbose_eval=10            # Print every 10 rounds\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred_proba = model.predict(dtest)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f} (of predicted ads, {precision*100:.1f}% are actually ads)\")\n",
    "print(f\"Recall:    {recall:.4f} (detected {recall*100:.1f}% of all ads)\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Ad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legitimate', 'Ad'],\n",
    "            yticklabels=['Legitimate', 'Ad'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Calculate false positive and false negative rates\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn)  # False Positive Rate\n",
    "fnr = fn / (fn + tp)  # False Negative Rate\n",
    "\n",
    "print(f\"\\nFalse Positive Rate: {fpr:.4f} ({fpr*100:.2f}%) - Legitimate sites blocked\")\n",
    "print(f\"False Negative Rate: {fnr:.4f} ({fnr*100:.2f}%) - Ads that got through\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance = model.get_score(importance_type='weight')\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': list(importance.keys()),\n",
    "    'importance': list(importance.values())\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Map feature indices back to names\n",
    "feature_names = X.columns.tolist()\n",
    "feature_importance['feature_name'] = feature_importance['feature'].apply(\n",
    "    lambda x: feature_names[int(x.replace('f', ''))] if x.startswith('f') else x\n",
    ")\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature_name'])\n",
    "plt.xlabel('Importance (Number of times used in trees)')\n",
    "plt.title('Top 15 Most Important Features for Ad Detection')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test on Example Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on example domains\n",
    "test_domains = [\n",
    "    # Known ads\n",
    "    'googleads.g.doubleclick.net',\n",
    "    'pagead2.googlesyndication.com',\n",
    "    'static.ads-twitter.com',\n",
    "    'an.facebook.com',\n",
    "    'adservice.google.com',\n",
    "    \n",
    "    # Known legitimate\n",
    "    'www.google.com',\n",
    "    'api.github.com',\n",
    "    'www.wikipedia.org',\n",
    "    'mail.yahoo.com',\n",
    "    'www.reddit.com'\n",
    "]\n",
    "\n",
    "print(\"Testing model on example domains:\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for domain in test_domains:\n",
    "    # Extract features\n",
    "    features = extractor.extract_features(domain)\n",
    "    \n",
    "    # Convert to DataFrame with same columns as training data\n",
    "    features_vec = pd.DataFrame([features])[X.columns]\n",
    "    features_vec = features_vec.fillna(0)\n",
    "    \n",
    "    # Predict\n",
    "    dmatrix = xgb.DMatrix(features_vec)\n",
    "    pred_proba = model.predict(dmatrix)[0]\n",
    "    prediction = \"AD\" if pred_proba > 0.5 else \"LEGITIMATE\"\n",
    "    \n",
    "    print(f\"{domain:45s} â†’ {prediction:12s} (confidence: {pred_proba:.3f})\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Model for Raspberry Pi Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in UBJ format (Universal Binary JSON - compact and fast)\n",
    "model.save_model('dns_adblocker_model.ubj')\n",
    "print(\"Model saved as: dns_adblocker_model.ubj\")\n",
    "\n",
    "# Also save in JSON format (human-readable)\n",
    "model.save_model('dns_adblocker_model.json')\n",
    "print(\"Model saved as: dns_adblocker_model.json\")\n",
    "\n",
    "# Save feature names for deployment\n",
    "import json\n",
    "with open('feature_names.json', 'w') as f:\n",
    "    json.dump(X.columns.tolist(), f, indent=2)\n",
    "print(\"Feature names saved as: feature_names.json\")\n",
    "\n",
    "# Print model info\n",
    "import os\n",
    "ubj_size = os.path.getsize('dns_adblocker_model.ubj') / 1024\n",
    "json_size = os.path.getsize('dns_adblocker_model.json') / 1024\n",
    "\n",
    "print(f\"\\nModel file sizes:\")\n",
    "print(f\"  UBJ format:  {ubj_size:.1f} KB (use this for production)\")\n",
    "print(f\"  JSON format: {json_size:.1f} KB (human-readable)\")\n",
    "print(f\"\\nâœ… Model ready for deployment on Raspberry Pi 5!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Model Summary & Deployment Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\n\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘               DNS AD-BLOCKER MODEL TRAINING COMPLETE                  â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ“Š DATASET:\n",
    "   â€¢ Total domains: {:,}\n",
    "   â€¢ Ad domains: {:,}\n",
    "   â€¢ Legitimate domains: {:,}\n",
    "   \n",
    "ğŸ¯ MODEL PERFORMANCE:\n",
    "   â€¢ Accuracy: {:.2f}%\n",
    "   â€¢ Precision: {:.2f}%\n",
    "   â€¢ Recall: {:.2f}%\n",
    "   â€¢ F1-Score: {:.2f}%\n",
    "   \n",
    "ğŸ”§ FEATURES:\n",
    "   â€¢ Total features: {}\n",
    "   â€¢ Feature types: Length, Character Distribution, Entropy, Keywords, Patterns\n",
    "   \n",
    "ğŸ’¾ OUTPUT FILES:\n",
    "   â€¢ dns_adblocker_model.ubj (model for production)\n",
    "   â€¢ dns_adblocker_model.json (human-readable)\n",
    "   â€¢ feature_names.json (feature list)\n",
    "   â€¢ confusion_matrix.png (visualization)\n",
    "   â€¢ feature_importance.png (visualization)\n",
    "\n",
    "ğŸš€ NEXT STEPS:\n",
    "   1. Copy dns_adblocker_model.ubj to your Raspberry Pi 5\n",
    "   2. Copy dns_feature_extractor.py to Raspberry Pi 5\n",
    "   3. Install: pip install xgboost tldextract dnslib\n",
    "   4. Run the DNS proxy server to start blocking ads!\n",
    "\n",
    "\"\"\".format(\n",
    "    len(df),\n",
    "    (y == 1).sum(),\n",
    "    (y == 0).sum(),\n",
    "    accuracy * 100,\n",
    "    precision * 100,\n",
    "    recall * 100,\n",
    "    f1 * 100,\n",
    "    X.shape[1]\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
